{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a17d57",
   "metadata": {},
   "source": [
    "# RSCPN\n",
    "\n",
    "This notebook shows how to solve the problem of corrupted traffic data recovery using RSCPN, the robust extension of SCPN considering unstructured, random anomalies. Note that the parameters used in this example may not necessarily optimal. For an in-depth discussion of RSCPN, please refer to our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786df5d4",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f683384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def compute_mae(var, var_hat):\n",
    "    return np.sum(np.abs(var-var_hat)) / var.shape[0]\n",
    "\n",
    "\n",
    "def Gradient_Descent(lamda, p, sigma, Iter=10):\n",
    "    '''\n",
    "    Parameters:\n",
    "        lamda: 1/rho\n",
    "        p: hyper-parameter p\n",
    "        sigma: the i-th singular value of matrix G\n",
    "        Iter: the number of iterations in solving x*\n",
    "    Output:\n",
    "        x*: float type\n",
    "    '''\n",
    "    x_k = sigma\n",
    "    for k in range(Iter):\n",
    "        x_k1 = sigma - lamda * p * (x_k) ** (p - 1)\n",
    "        x_k = x_k1\n",
    "\n",
    "    return x_k\n",
    "\n",
    "def opt_x(G, lamda, p, tau):\n",
    "    '''\n",
    "    Parameters:\n",
    "        G: 2-d matrix\n",
    "        lamda: 1/rho\n",
    "        p: hyper-parameter p\n",
    "        tau: hyper-parameter tau (compared with singular value)\n",
    "    Output:\n",
    "        W: transformed G (with singular matrix changed)\n",
    "    '''\n",
    "\n",
    "    [Q, sigma, R] = np.linalg.svd(G, full_matrices=0)\n",
    "    delta = np.zeros(sigma.shape)  # singular vector\n",
    "\n",
    "    v = (2 * lamda * (1 - p)) ** (1 / (2 - p))\n",
    "    v1 = v + lamda * p * (v ** (p - 1))\n",
    "\n",
    "    for i in range(len(sigma)):\n",
    "        s = sigma[i]\n",
    "        if s >= v1:\n",
    "            x_ = Gradient_Descent(lamda, p, s)\n",
    "        else:\n",
    "            x_ = 0\n",
    "\n",
    "        tau_ = ((1 / (2 * lamda)) * ((x_ - s) ** 2) + x_ ** p) ** (1 / p)\n",
    "        if tau <= tau_:\n",
    "            delta[i] = s\n",
    "        else:\n",
    "            delta[i] = x_\n",
    "\n",
    "    return np.matmul(np.matmul(Q, np.diag(delta)), R)\n",
    "\n",
    "def add_outlier(sparse_tensor, s, γ):\n",
    "    '''add the outlier corruption the observations (sparse_tensor)\n",
    "       s: mean magnitude of outliers\n",
    "       λ: corruption level\n",
    "    '''\n",
    "    np.random.seed(1000)\n",
    "    ## position of obervations\n",
    "    pos_observe = np.where(sparse_tensor != 0)\n",
    "    ## copy the observations\n",
    "    corrsparse_tensor = sparse_tensor.copy()\n",
    "    ## size of observations\n",
    "    obser_size = corrsparse_tensor[pos_observe].shape\n",
    "    ## generate the corruption term\n",
    "    corr = np.random.uniform(low = -1*s, high= s, size = obser_size)\n",
    "    ## randomly sampled the sparse corruption term with fraction of γ\n",
    "    corr_term = np.multiply(corr, np.round(np.random.rand(obser_size[0]) - 0.5 + γ ))\n",
    "    ## add the sparse corruption to the obervations\n",
    "    corrsparse_tensor[pos_observe] = corrsparse_tensor[pos_observe] + corr_term\n",
    "    ## []+\n",
    "    corrsparse_tensor = np.maximum(corrsparse_tensor,0)\n",
    "    return corrsparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ca07",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03307e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSCPN(dense_tensor, cor_sparse_tensor, lam, alpha, rho, p, tau, epsilon, pos_missing, pos_test, maxiter=100):\n",
    "    '''\n",
    "    Parameters:\n",
    "        dense_tensor: the original tensor (without mask) ∈ (M * I * J)\n",
    "        sparse_tensor: the observed tensor (with mask) ∈ (M * I * J)\n",
    "        alpha: the weight for each tensor mode, [0.3, 0.3, 0.3]\n",
    "        rho: learning rate\n",
    "        p: hyper-parameter p\n",
    "        tau: hypter-parameter tau\n",
    "        epsilon: the threshold for residual\n",
    "        maxiter: the maximum iterations, default = 200\n",
    "    Output:\n",
    "        return a predicted tensor, the same size with dense_tensor\n",
    "    '''\n",
    "\n",
    "    dim = np.array(cor_sparse_tensor.shape)  # dim = [M, I, J]\n",
    "\n",
    "    #     min-max normalize\n",
    "    min_value = ten2mat(dense_tensor, 0).min(axis=1)\n",
    "    max_value = ten2mat(dense_tensor, 0).max(axis=1)\n",
    "    cor_sparse_tensor = (cor_sparse_tensor - min_value[:, np.newaxis, np.newaxis]) / (\n",
    "                max_value[:, np.newaxis, np.newaxis] - min_value[:, np.newaxis, np.newaxis])\n",
    "    cor_sparse_tensor[pos_missing] = 0\n",
    "\n",
    "    # initialization\n",
    "    M = cor_sparse_tensor.copy()  # (M * I * J), M = mat2ten(Z, dim, 0)\n",
    "    X = cor_sparse_tensor.copy()\n",
    "    X3 = np.zeros(np.insert(dim, 0, len(dim)))  # 4-D tensor\n",
    "    T3 = np.zeros(np.insert(dim, 0, len(dim)))  # 4-D tenosr\n",
    "    E = np.zeros(dim)\n",
    "    E3 = np.zeros(np.insert(dim, 0, len(dim)))\n",
    "    it = 0\n",
    "\n",
    "    # update iteratively\n",
    "    while True:\n",
    "        rho = min(rho * 1.4, 1e5)\n",
    "\n",
    "        # update X 4-D tensor\n",
    "        X_t = X.copy()\n",
    "        for k in range(len(dim)):\n",
    "            X3[k] = mat2ten(\n",
    "                opt_x(ten2mat(M - E3[k] - T3[k] / rho, k), 1 / rho, p, tau[k]),\n",
    "                dim,\n",
    "                k)\n",
    "\n",
    "        # update M\n",
    "        M[pos_missing] = np.mean(X3 + E3 + T3 / rho, axis=0)[pos_missing]\n",
    "\n",
    "        # update E\n",
    "        for k in range(len(dim)):\n",
    "            H = M - X3[k] - T3[k] / rho\n",
    "            E3[k] = np.multiply(np.sign(H), np.maximum(0, np.abs(H) - lam / rho))\n",
    "\n",
    "        X = np.einsum('k, kmnt -> mnt', alpha, X3)  # (M * I * J)\n",
    "        E = np.einsum('k, kmnt -> mnt', alpha, E3)  # (M * I * J)\n",
    "\n",
    "        # update T 4-D tensor\n",
    "        T3 = T3 + rho * (X3 + E3 - np.broadcast_to(M, np.insert(dim, 0, len(dim))))\n",
    "\n",
    "        # denormalize\n",
    "        X = X * (max_value[:, np.newaxis, np.newaxis] - min_value[:, np.newaxis, np.newaxis]) + min_value[:, np.newaxis, np.newaxis]\n",
    "        E = E * (max_value[:, np.newaxis, np.newaxis] - min_value[:, np.newaxis, np.newaxis]) + min_value[:, np.newaxis, np.newaxis]\n",
    "\n",
    "        # check tolerance\n",
    "        tol = np.sqrt(np.sum((X - X_t) ** 2)) / np.sqrt(np.sum(X_t ** 2))\n",
    "\n",
    "        it += 1\n",
    "\n",
    "        # terminate\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    # accuracy\n",
    "    print('Total iteration: {}'.format(it + 1))\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], X[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], X[pos_test])))\n",
    "    print('Imputation MAE: {:.6}'.format(compute_mae(dense_tensor[pos_test], X[pos_test])))\n",
    "    print()\n",
    "\n",
    "    return X, E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1cdb3",
   "metadata": {},
   "source": [
    "## A toy example on PEMS volume dataset (40% random missing scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5dda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 62, 288)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('dataset/PEMS08/pems08_288_62_170.mat')\n",
    "\n",
    "dense_tensor = tensor['T']\n",
    "dense_tensor = dense_tensor.transpose(2,1,0)\n",
    "print(dense_tensor.shape)\n",
    "dim = dense_tensor.shape\n",
    "np.random.seed(1)\n",
    "\n",
    "missing_rate = 0.4\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "\n",
    "pos_missing = np.where(sparse_tensor == 0)  # all missing values, including original missing and mask missing, = (M * IJ)\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))  # only include mask missing, = (M * I * J)\n",
    "\n",
    "dense_tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa83adb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cor_rate = 0.10\n",
      "Total iteration: 33\n",
      "Imputation MAPE: 0.0862123\n",
      "Imputation RMSE: 22.3963\n",
      "Imputation MAE: 12.9094\n",
      "\n",
      "cor_rate = 0.20\n",
      "Total iteration: 33\n",
      "Imputation MAPE: 0.087379\n",
      "Imputation RMSE: 22.3248\n",
      "Imputation MAE: 13.0158\n",
      "\n",
      "cor_rate = 0.30\n",
      "Total iteration: 33\n",
      "Imputation MAPE: 0.0924497\n",
      "Imputation RMSE: 23.3016\n",
      "Imputation MAE: 13.516\n",
      "\n",
      "cor_rate = 0.40\n",
      "Total iteration: 32\n",
      "Imputation MAPE: 0.0962132\n",
      "Imputation RMSE: 23.3616\n",
      "Imputation MAE: 13.9809\n",
      "\n",
      "cor_rate = 0.50\n",
      "Total iteration: 32\n",
      "Imputation MAPE: 0.101351\n",
      "Imputation RMSE: 23.4729\n",
      "Imputation MAE: 14.2306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cor_rate in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    cor_sparse_tensor = add_outlier(sparse_tensor, 100, cor_rate)\n",
    "    alpha = np.ones(3) / 3\n",
    "    p = 0.5\n",
    "    lamda = 1e5\n",
    "    rho = 1/lamda\n",
    "    epsilon = 1e-3\n",
    "    maxiter = 100\n",
    "    lam = 1/((dim[0] * dim[2]) ** 0.5)\n",
    "    if cor_rate in [0.1, 0.2]:\n",
    "        tau = [10, 10, 10]\n",
    "    elif cor_rate in [0.3, 0.4]:\n",
    "        tau = [30, 30, 30]\n",
    "    else:\n",
    "        tau = [50, 50, 50]\n",
    "    \n",
    "    print('cor_rate = %.2f' % cor_rate)\n",
    "\n",
    "    tensor_hat, E_hat = RSCPN(dense_tensor, cor_sparse_tensor, lam, alpha, rho, p, tau, epsilon, pos_missing, pos_test, maxiter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212f974",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "This work is released under the MIT license."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
